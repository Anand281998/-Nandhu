{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "      <th>X20</th>\n",
       "      <th>X21</th>\n",
       "      <th>X22</th>\n",
       "      <th>X23</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X1 X2 X3 X4  X5  X6 X7  X8  X9 X10 ...   X15   X16   X17 X18   X19  \\\n",
       "1   20000  2  2  1  24   2  2  -1  -1  -2 ...     0     0     0   0   689   \n",
       "2  120000  2  2  2  26  -1  2   0   0   0 ...  3272  3455  3261   0  1000   \n",
       "\n",
       "    X20   X21 X22   X23  Y  \n",
       "1     0     0   0     0  1  \n",
       "2  1000  1000   0  2000  1  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "z = pd.read_excel('G:\\Data Sets\\default_of_creditcard_clients.xls')\n",
    "z = z.drop(z.index[[0]])\n",
    "z.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the data into feature and label variables\n",
    "x = z.drop(['Y'],axis =1)\n",
    "y = pd.get_dummies(z.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the given data\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "lr_rate = 0.5\n",
    "epochs = 100\n",
    "batch_size = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Parameters\n",
    "n_input = 23\n",
    "h_l1 = 10\n",
    "h_l2 = 10\n",
    "n_class = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the placeholder\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the coefficients\n",
    "W = {'h1':tf.Variable(tf.random_normal([n_input,h_l1])),\n",
    "     'h2':tf.Variable(tf.random_normal([h_l1,h_l2])),\n",
    "    'out':tf.Variable(tf.random_normal([h_l2,n_class]))}\n",
    "\n",
    "B = {'h1':tf.Variable(tf.random_normal([h_l1])),\n",
    "     'h2':tf.Variable(tf.random_normal([h_l2])),\n",
    "    'out':tf.Variable(tf.random_normal([n_class]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the layers\n",
    "def neu_network(X):\n",
    "    layer_1 = tf.add(tf.matmul(X,W['h1']),B['h1'])\n",
    "    l1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    layer_2 =tf.add(tf.matmul(l1,W['h2']),B['h2'])\n",
    "    l2 = tf.nn.sigmoid(layer_2)\n",
    "    \n",
    "    layer_out = tf.add(tf.matmul(l2,W['out']),B['out'])\n",
    "    return layer_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the function\n",
    "y_out = neu_network(X)\n",
    "#y_out = tf.reduce_sum(y_out,axis = 1)\n",
    "y_output = tf.nn.softmax(y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the loss/cost function \n",
    "y_clip = tf.clip_by_value(y_output , 1e-10 ,1.0)\n",
    "loss_fun = tf.reduce_mean(tf.reduce_sum(Y * tf.log(y_clip) + (1 - Y) * tf.log(1 - y_clip) , axis  = 1))\n",
    "\n",
    "# Optimization\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate = lr_rate).minimize(loss_fun)\n",
    "\n",
    "corr_pred = tf.equal(tf.argmax(y_out,1),tf.argmax(Y,1))\n",
    "\n",
    "acc = tf.reduce_mean(tf.cast(corr_pred,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intializing the global variable\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ---- cost: -1.1482514 ---- ---- Training Accuracy: 0.777\n",
      "Epoch: 1 ---- cost: -1.2701373 ---- ---- Training Accuracy: 0.7773333\n",
      "Epoch: 2 ---- cost: -1.6729653 ---- ---- Training Accuracy: 0.77741665\n",
      "Epoch: 3 ---- cost: -2.3779535 ---- ---- Training Accuracy: 0.77741665\n",
      "Epoch: 4 ---- cost: -3.208872 ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 5 ---- cost: -4.0644083 ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 6 ---- cost: -4.92432 ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 7 ---- cost: -5.788776 ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 8 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 9 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 10 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 11 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 12 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 13 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 14 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 15 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 16 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 17 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 18 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 19 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 20 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 21 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 22 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 23 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 24 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 25 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 26 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 27 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 28 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 29 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 30 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 31 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 32 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 33 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 34 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 35 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 36 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 37 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 38 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 39 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 40 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 41 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 42 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 43 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 44 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 45 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 46 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 47 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 48 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 49 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 50 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 51 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 52 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 53 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 54 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 55 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 56 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 57 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 58 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 59 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 60 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 61 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 62 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 63 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 64 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 65 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 66 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 67 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 68 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 69 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 70 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 71 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 72 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 73 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 74 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 75 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 76 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 77 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 78 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 79 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 80 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 81 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 82 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 83 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 84 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 85 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 86 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 87 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 88 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 89 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 90 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 91 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 92 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 93 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 94 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 95 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 96 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 97 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 98 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n",
      "Epoch: 99 ---- cost: nan ---- ---- Training Accuracy: 0.7775\n"
     ]
    }
   ],
   "source": [
    "# Training the data\n",
    "for epoch in range(epochs):\n",
    "    sess.run(opt , feed_dict = {X : x_train , Y : y_train})\n",
    "    lf = sess.run(loss_fun,feed_dict = {X:x_train , Y : y_train})\n",
    "    Accuracy = sess.run(acc , feed_dict = {X:x_train , Y:y_train})\n",
    "    print(\"Epoch:\",epoch  ,'----','cost:',lf,'----','----','Training Accuracy:',Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy 78.39999794960022\n"
     ]
    }
   ],
   "source": [
    "print(\"testing accuracy\",sess.run(acc,feed_dict = {X:x_test,Y:y_test})*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
